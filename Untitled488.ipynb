{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "627ef860-3a75-43c1-9480-3e5459e65feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "ALL CSVs & GRAPHS GENERATED SUCCESSFULLY ✅\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import json\n",
    "import yaml\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ============================\n",
    "# PATH CONFIG\n",
    "# ============================\n",
    "\n",
    "BASE_PATH = r\"C:\\Users\\NXTWAVE\\Downloads\\Justice Delay Analytics for Senior Citizen Cases (Karnataka HC)\"\n",
    "CSV_PATH = os.path.join(BASE_PATH, \"casesdisposedofseniorcitizenHCKBengaluru_3.csv\")\n",
    "\n",
    "RESULT_CSV = os.path.join(BASE_PATH, \"actual_vs_predicted_results.csv\")\n",
    "PREDICTION_CSV = os.path.join(BASE_PATH, \"future_predictions.csv\")\n",
    "\n",
    "# Graphs\n",
    "LOSS_GRAPH = os.path.join(BASE_PATH, \"accuracy_loss_graph.png\")\n",
    "HEATMAP_GRAPH = os.path.join(BASE_PATH, \"heatmap_cases.png\")\n",
    "COMPARISON_GRAPH = os.path.join(BASE_PATH, \"actual_vs_predicted.png\")\n",
    "RESULT_GRAPH = os.path.join(BASE_PATH, \"results_trend.png\")\n",
    "PREDICTION_GRAPH = os.path.join(BASE_PATH, \"future_forecast.png\")\n",
    "\n",
    "# ============================\n",
    "# LOAD & CLEAN DATA\n",
    "# ============================\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df.columns = [c.strip().lower().replace(\".\", \"\").replace(\" \", \"_\") for c in df.columns]\n",
    "\n",
    "df = df[[\"month\", \"year\", \"count\"]].dropna()\n",
    "df[\"year\"] = df[\"year\"].astype(int)\n",
    "df[\"count\"] = df[\"count\"].astype(float)\n",
    "\n",
    "df[\"month\"] = df[\"month\"].astype(str).str.strip().str.title()\n",
    "\n",
    "month_map = {\n",
    "    \"January\":1,\"February\":2,\"March\":3,\"April\":4,\"May\":5,\"June\":6,\n",
    "    \"July\":7,\"August\":8,\"September\":9,\"October\":10,\"November\":11,\"December\":12\n",
    "}\n",
    "df[\"month_num\"] = df[\"month\"].map(month_map)\n",
    "df.dropna(inplace=True)\n",
    "df[\"month_num\"] = df[\"month_num\"].astype(int)\n",
    "\n",
    "# ============================\n",
    "# HEATMAP\n",
    "# ============================\n",
    "\n",
    "pivot = df.pivot_table(\n",
    "    values=\"count\",\n",
    "    index=\"year\",\n",
    "    columns=\"month_num\",\n",
    "    aggfunc=\"sum\"\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(pivot, cmap=\"YlOrRd\", annot=True, fmt=\".0f\")\n",
    "plt.title(\"Heatmap of Senior Citizen Case Disposal\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Year\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(HEATMAP_GRAPH)\n",
    "plt.close()\n",
    "\n",
    "# ============================\n",
    "# FEATURES & SCALING\n",
    "# ============================\n",
    "\n",
    "X = df[[\"year\", \"month_num\"]].values\n",
    "y = df[\"count\"].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ============================\n",
    "# TRAIN TEST SPLIT\n",
    "# ============================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# MODEL\n",
    "# ============================\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(32, activation=\"relu\", input_shape=(2,)),\n",
    "    Dense(16, activation=\"relu\"),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=20, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=300,\n",
    "    batch_size=8,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# ACCURACY / LOSS GRAPH\n",
    "# ============================\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.title(\"Model Accuracy (Loss Curve)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(LOSS_GRAPH)\n",
    "plt.close()\n",
    "\n",
    "# ============================\n",
    "# EVALUATION\n",
    "# ============================\n",
    "\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    \"Actual\": y_test,\n",
    "    \"Predicted\": y_pred\n",
    "})\n",
    "\n",
    "result_df.to_csv(RESULT_CSV, index=False)\n",
    "\n",
    "# ============================\n",
    "# COMPARISON GRAPH\n",
    "# ============================\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(result_df[\"Actual\"].values, label=\"Actual\", marker=\"o\")\n",
    "plt.plot(result_df[\"Predicted\"].values, label=\"Predicted\", marker=\"x\")\n",
    "plt.title(\"Actual vs Predicted Comparison\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(COMPARISON_GRAPH)\n",
    "plt.close()\n",
    "\n",
    "# ============================\n",
    "# RESULT TREND GRAPH\n",
    "# ============================\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.regplot(\n",
    "    x=result_df.index,\n",
    "    y=result_df[\"Predicted\"],\n",
    "    scatter=False,\n",
    "    label=\"Prediction Trend\"\n",
    ")\n",
    "plt.title(\"Prediction Trend Line\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULT_GRAPH)\n",
    "plt.close()\n",
    "\n",
    "# ============================\n",
    "# FUTURE PREDICTIONS (12 MONTHS)\n",
    "# ============================\n",
    "\n",
    "last_year = df[\"year\"].max()\n",
    "\n",
    "future_rows = [[last_year + 1, m] for m in range(1,13)]\n",
    "future_df = pd.DataFrame(future_rows, columns=[\"year\",\"month_num\"])\n",
    "\n",
    "future_scaled = scaler.transform(future_df.values)\n",
    "future_preds = model.predict(future_scaled).flatten()\n",
    "\n",
    "future_df[\"predicted_count\"] = future_preds\n",
    "future_df.to_csv(PREDICTION_CSV, index=False)\n",
    "\n",
    "# ============================\n",
    "# FUTURE PREDICTION GRAPH\n",
    "# ============================\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(future_df[\"month_num\"], future_df[\"predicted_count\"], marker=\"o\")\n",
    "plt.title(\"Future 12-Month Case Disposal Forecast\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Predicted Cases\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(PREDICTION_GRAPH)\n",
    "plt.close()\n",
    "\n",
    "print(\"ALL CSVs & GRAPHS GENERATED SUCCESSFULLY ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1be0b71-4b6e-428e-9e43-3a8098e5c8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
